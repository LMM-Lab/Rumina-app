import asyncio
import json
import uuid
from dataclasses import dataclass, field
from typing import Optional

import numpy as np
import scipy.io.wavfile as wav
from api.modules.response_generation.vlm.types import GenerationResult
from api.utils.invalid_transcription import is_invalid_transcription
from api.utils.model_selector import (
    get_response_instance,
    get_transcriber_instance,
    get_tts_instance,
)
from api.utils.model_set import make_set_id
from asyncpg import Pool
from db.session import get_pool
from fastapi import APIRouter, WebSocket, WebSocketDisconnect

router = APIRouter()

MAX_HISTORY = 5
conversation_history: list[dict] = []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class UtteranceTask:
    id: str
    speech_id: int
    cancel_event: asyncio.Event = field(default_factory=asyncio.Event)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆä»»æ„ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_debug_wav(pcm: bytes, sr: int = 16_000, prefix="debug"):
    try:
        fname = f"{prefix}_{uuid.uuid4().hex[:8]}.wav"
        wav.write(fname, sr, np.frombuffer(pcm, np.int16))
        print("ğŸ’¾ save", fname)
    except Exception as e:
        print("save_debug_wav error:", e)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ WS ãƒãƒ³ãƒ‰ãƒ© â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.websocket("/ws/m/image")
async def we_image_endpoint(ws: WebSocket):
    await ws.accept()
    print("âœ… WS accepted")

    session_id = str(uuid.uuid4())
    turn_index = 0

    init = await ws.receive_json()
    model_name = init.get("model", "rumina-m2")
    vad_silence_ms = init.get("vad_silence_threshold", 1000)
    print(f"ğŸ“ model={model_name}  vad={vad_silence_ms}ms")

    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
    transcriber = get_transcriber_instance(model_name)
    await transcriber.start()
    vlm = get_response_instance(model_name)
    tts = get_tts_instance(model_name)

    # model æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
    print(f"STT_name: {transcriber.model_name}")
    print(f"TTS_name: {tts.model_name}")
    print(f"VLM_name: {vlm.model_name}")

    # ãƒ¢ãƒ‡ãƒ« ID ã‚’å–å¾—
    stt_id = transcriber.model_name
    tts_id = tts.model_name
    vlm_id = vlm.model_name

    # â”€â”€â”€â”€â”€â”€ ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã® upsert â”€â”€â”€â”€â”€â”€
    # å†ç¾å¯èƒ½ãª model_set_id ã‚’ä½œæˆ
    model_set_id = make_set_id(
        stt_id=stt_id,
        vlm_id=vlm_id,
        tts_id=tts_id,
        filler_id=None,
        set_type="single",
    )

    # DB ã« upsertï¼ˆãªã‘ã‚Œã° INSERTã€ã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    pool: Pool = await get_pool()
    async with pool.acquire() as conn:
        async with conn.transaction():
            await conn.execute(
                """
                INSERT INTO model_set_catalog (set_id, set_type, stt_id, vlm_id, tts_id)
                VALUES ($1, 'single', $2, $3, $4)
                ON CONFLICT (set_id) DO NOTHING
                """,
                model_set_id,
                stt_id,
                vlm_id,
                tts_id,
            )
            print(f"Model set upserted: {model_set_id}")

    transcriber.set_silence_threshold(max((vad_silence_ms / 1000) - 0.3, 0.05))

    # â”€â”€â”€â”€â”€â”€ çŠ¶æ…‹å¤‰æ•° â”€â”€â”€â”€â”€â”€
    audio_buf = bytearray()
    current_task: Optional[UtteranceTask] = None
    current_speech_id = 0
    buffer_speech_id = 0  # â˜… STARTã€œEND é–“ã® ID
    pending_ids: asyncio.Queue[int] = asyncio.Queue()

    # â”€â”€â”€â”€â”€â”€ éŸ³å£°ã¨ç”»åƒå—ä¿¡ â”€â”€â”€â”€â”€â”€
    async def recv_loop():
        nonlocal current_task, current_speech_id, buffer_speech_id
        while True:
            try:
                msg = await ws.receive()

                # === ãƒ†ã‚­ã‚¹ãƒˆ control ===
                if msg["type"] == "websocket.receive" and "text" in msg:
                    data = json.loads(msg["text"])

                    # --- START ---
                    if data["type"] == "active_audio_start":
                        current_speech_id += 1
                        buffer_speech_id = current_speech_id
                        audio_buf.clear()
                        print("ğŸ™ï¸ START", current_speech_id)

                        if current_task:
                            current_task.cancel_event.set()

                        if img := data.get("image_base64"):
                            transcriber.update_latest_image(img)

                    # --- END ---
                    elif data["type"] == "active_audio_end":
                        print("ğŸ›‘ END -> transcribe")
                        await transcriber.transcribe_audio_chunk(
                            bytes(audio_buf)
                        )
                        await pending_ids.put(buffer_speech_id)

                # === ãƒã‚¤ãƒŠãƒªï¼ˆPCMï¼‰ ===
                elif "bytes" in msg:
                    audio_buf.extend(msg["bytes"])

            except Exception as e:
                print("recv_loop error:", e)
                break

    # â”€â”€â”€â”€â”€â”€ è»¢å†™ â†’ LLM/TTS â”€â”€â”€â”€â”€â”€
    async def trans_loop():
        nonlocal current_task, current_speech_id, turn_index
        while True:
            try:
                result = await transcriber.result_queue.get()
                text = result["text"]
                stt_latency = result["latency_ms"]
                print(f"ğŸ”¡ STT latency: {stt_latency}ms, text={text}")
                speech_id = await pending_ids.get()  # â˜… å¯¾å¿œIDå–å¾—
                print("ğŸ“ text:", text, "sid:", speech_id)

                # ç„¡åŠ¹ or ç©ºæ–‡å­—ã‚¹ã‚­ãƒƒãƒ—
                if isinstance(text, dict):
                    text = text.get("text", "")
                if is_invalid_transcription(text):
                    continue

                await ws.send_json({"type": "transcription", "message": text})

                # å±¥æ­´
                hist = [
                    {
                        "role": "system",
                        "content": "You are a helpful assistant.",
                    }
                ]
                hist.extend(conversation_history[-MAX_HISTORY * 2 :])
                hist.append({"role": "user", "content": text})

                # ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
                task = UtteranceTask(
                    id=f"assistant_{uuid.uuid4().hex[:8]}", speech_id=speech_id
                )
                current_task = task
                turn_index += 1
                asyncio.create_task(
                    handle_utterance(
                        task,
                        text,
                        transcriber.latest_image_base64,
                        hist,
                        session_id,
                        turn_index,
                        model_set_id,
                        pool,
                        stt_latency,
                    )
                )
            except Exception as e:
                print("trans_loop error:", e)
                break

    # â”€â”€â”€â”€â”€â”€ å¿œç­”ç”Ÿæˆ & TTS â”€â”€â”€â”€â”€â”€
    async def handle_utterance(
        task: UtteranceTask,
        user_text: str,
        img_b64: str | None,
        hist: list,
        session_id: str,
        turn_index: int,
        model_set_id: str,
        pool: Optional[Pool],
        stt_latency: int,
    ):
        nonlocal current_speech_id

        # LLM
        vlm_start = asyncio.get_event_loop().time()
        result: GenerationResult = await vlm.generate(
            message=user_text,
            image_base64=img_b64,
            history=hist,
        )
        vlm_latency = int((asyncio.get_event_loop().time() - vlm_start) * 1000)

        vlm_tokens_in = result.prompt_tokens
        vlm_tokens_out = result.completion_tokens

        vlm_tok_per_sec = (
            vlm_tokens_out / (vlm_latency / 1000) if vlm_latency > 0 else None
        )

        resp_text = result.content

        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«åˆ¤å®šâ‘ 
        if task.cancel_event.is_set() or task.speech_id != current_speech_id:
            await ws.send_json(
                {
                    "type": "assistant_final",
                    "id": task.id,
                    "message": resp_text,
                    "audio": False,
                    "prompt": user_text,
                }
            )
            return

        # TTS
        tts_start = asyncio.get_event_loop().time()
        tts_latency = None
        try:
            audio64 = await asyncio.to_thread(
                tts.synthesize_to_base64, resp_text
            )
        except Exception as e:
            print("TTS failed:", e)
            await ws.send_json(
                {
                    "type": "assistant_final",
                    "id": task.id,
                    "message": resp_text,
                    "audio": False,
                }
            )
            return

        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«åˆ¤å®šâ‘¡
        if task.cancel_event.is_set() or task.speech_id != current_speech_id:
            await ws.send_json(
                {
                    "type": "assistant_final",
                    "id": task.id,
                    "message": resp_text,
                    "audio": False,
                }
            )
        else:

            tts_latency = int(
                (asyncio.get_event_loop().time() - tts_start) * 1000
            )
            print(f"ğŸµ TTS latency: {tts_latency}ms")
            await ws.send_json(
                {
                    "type": "ai_response",
                    "id": task.id,
                    "message": resp_text,
                    "audio_base64": audio64,
                }
            )

        # å±¥æ­´è¿½åŠ 
        conversation_history.append(
            {"role": "assistant", "content": resp_text}
        )
        if len(conversation_history) > MAX_HISTORY * 2:
            conversation_history[:] = conversation_history[-MAX_HISTORY * 2 :]

        # --- ç·ã‚¿ãƒ¼ãƒ³ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ ---
        if tts_latency is None:
            total_latency = stt_latency + vlm_latency
        else:
            total_latency = stt_latency + vlm_latency + tts_latency

        # â€”â€”â€”â€” DB ã¸ãƒ­ã‚°æŒ¿å…¥ â€”â€”â€”â€”
        if pool is not None:
            async with pool.acquire() as conn:
                await conn.execute(
                    """
                    INSERT INTO single_turns (
                    request_id,
                    session_id,
                    turn_index,
                    timestamp_utc,
                    model_set_id,

                    stt_latency_ms,
                    transcript,

                    vlm_latency_ms,
                    vlm_tokens_in,
                    vlm_tokens_out,
                    vlm_tok_per_sec,

                    tts_latency_ms,

                    total_turn_latency_ms,
                    net_up_ms,
                    net_down_ms,
                    error_flag
                    ) VALUES (
                    gen_random_uuid()::text,
                    $1, $2, now(), $3,

                    $4, $5,

                    $6, $7, $8, $9,

                    $10,

                    $11, NULL, NULL, NULL
                    )
                    """,
                    # $1â€¦$10 ã®å¯¾å¿œ
                    session_id,  # $1
                    turn_index,  # $2
                    model_set_id,  # $3
                    stt_latency,  # $4: stt_latency_ms
                    user_text,  # $5: transcript
                    vlm_latency,  # $6
                    vlm_tokens_in,  # $7: vlm_tokens_in ä»®
                    vlm_tokens_out,  # $8: vlm_tokens_out ä»®
                    vlm_tok_per_sec,  # $9: vlm_tok_per_sec
                    tts_latency,  # $10: tts_latency_ms
                    total_latency,  # $11: total_turn_latency_ms
                )
        else:
            print("DB pool is None, skipping DB insert.")

    # â”€â”€â”€â”€â”€â”€ èµ°ã‚‰ã›ã‚‹ â”€â”€â”€â”€â”€â”€
    recv_task = asyncio.create_task(recv_loop())
    trans_task = asyncio.create_task(trans_loop())

    try:
        await asyncio.gather(recv_task, trans_task)
    except WebSocketDisconnect:
        print("âŒ WS disconnected")
    finally:
        recv_task.cancel()
        trans_task.cancel()
        await transcriber.stop()
        print("ğŸ›‘ session closed")
