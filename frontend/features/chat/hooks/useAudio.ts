import { useEffect, useRef, useState, useCallback } from "react";

export const useAudio = () => {
    const instanceId = useRef(Math.random());
    console.log("useAudio instance ID:", instanceId.current);
    const [isRecording, setIsRecording] = useState(false);
    const audioContextRef = useRef<AudioContext | null>(null);
    const [transcriptions, setTranscriptions] = useState<string[]>([]);
    const socketRef = useRef<WebSocket | null>(null);
    const mediaStreamRef = useRef<MediaStream | null>(null);
    const workletNodeRef = useRef<AudioWorkletNode | null>(null);

    useEffect(() => {
        if (!navigator.mediaDevices?.getUserMedia) {
            alert("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯ãƒžã‚¤ã‚¯éŒ²éŸ³ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã›ã‚“ã€‚");
        }
    }, []);

    const stopRecording = useCallback(() => {
        if (workletNodeRef.current) {
            workletNodeRef.current.port.postMessage({ type: "stop" });
            workletNodeRef.current.disconnect();
        }
        if (audioContextRef.current) audioContextRef.current.close();
        if (mediaStreamRef.current) {
            mediaStreamRef.current.getTracks().forEach((track) => track.stop());
        }
        if (socketRef.current) socketRef.current.close();
        setIsRecording(false);
    }, []);

    useEffect(() => {
        return () => {
            console.log("ðŸ§¹ AudioProviderãŒã‚¢ãƒ³ãƒžã‚¦ãƒ³ãƒˆã•ã‚ŒãŸã®ã§éŒ²éŸ³åœæ­¢");
            stopRecording();
        };
    }, [stopRecording]);

    const startRecording = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaStreamRef.current = stream;

            const audioContext = new AudioContext({ sampleRate: 16000 });
            audioContextRef.current = audioContext;

            const socket = new WebSocket("ws://localhost:8000/ws/audio");
            socket.binaryType = "arraybuffer";
            socketRef.current = socket;

            socket.onmessage = (event) => {
                const transcription = event.data;
                console.log("å—ä¿¡ã—ãŸæ–‡å­—èµ·ã“ã—çµæžœ:", transcription);
                // ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãƒ¼é–¢æ•°å†…ã§æ›´æ–°å‰å¾Œã®é…åˆ—ã‚’ãƒ­ã‚°å‡ºåŠ›ã™ã‚‹
                setTranscriptions((prev) => {
                    console.log("æ›´æ–°å‰ã® transcriptions:", prev);
                    const newTranscriptions = [...prev, transcription];
                    console.log("æ›´æ–°å¾Œã® transcriptions:", newTranscriptions);
                    return newTranscriptions;
                });
            };

            await audioContext.audioWorklet.addModule("/worklet/processor.js");
            const workletNode = new AudioWorkletNode(audioContext, "audio-processor");
            workletNodeRef.current = workletNode;

            const source = audioContext.createMediaStreamSource(stream);
            source.connect(workletNode);
            workletNode.connect(audioContext.destination);

            workletNode.port.onmessage = (event) => {
                if (event.data?.type === "audio") {
                    if (socket.readyState === WebSocket.OPEN) {
                        socket.send(event.data.buffer);
                    }
                }
            };

            socket.onopen = () => {
                setIsRecording(true);
            };

            socket.onerror = (e) => {
                console.error("WebSocket error:", e);
            };
        } catch (error) {
            console.error("éŒ²éŸ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ:", error);
        }
    };

    const toggleRecording = () => {
        if (isRecording) {
            stopRecording();
        } else {
            startRecording();
        }
    };

    return {
        instanceId: instanceId.current,
        isRecording,
        toggleRecording,
        transcriptions,
    };
};
